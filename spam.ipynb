{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total samples:  5573\n",
      "ham:  4825\n",
      "spam:  748\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 2 artists>"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = pd.read_csv('/home/vi/HCMUS/work/learn/caro/text_classification/spam_detection.csv', header=None)\n",
    "print(\"total samples: \", data[0].count())\n",
    "data = (data[0] == \"ham\").to_numpy()\n",
    "\n",
    "ham = data.sum()\n",
    "spam = data.size - ham\n",
    "\n",
    "print(\"ham: \", ham)\n",
    "print(\"spam: \", spam)\n",
    "\n",
    "plt.bar([\"ham\", \"spam\"], [ham, spam])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_map = {'\\0':0}\n",
    "sentence_len = 32\n",
    "data_dir = './data/spam.csv'\n",
    "train_test_pro = 0.7\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def initData(data_directory = '/home/vi/HCMUS/work/learn/caro/text_classification/spam_detection.csv'):\n",
    "    k = 0\n",
    "    data_ = {0 : [], 1 : []}\n",
    "    data = pd.read_csv(data_directory, header=None)\n",
    "\n",
    "    for i in range(len(data[0])):\n",
    "        data[1][i] = [word for word in word_tokenize(data[1][i]) if word not in stop_words]\n",
    "        for word in data[1][i]:\n",
    "            if word not in words_map:\n",
    "                words_map[word] = k\n",
    "                k += 1\n",
    "        data[1][i] = [words_map[word] for word in data[1][i]]\n",
    "        data[1][i] = [0] * (sentence_len - len(data[1][i])) + data[1][i]\n",
    "        data[1][i] = torch.tensor(data[1][i])\n",
    "        if data[0][i] == 'ham':\n",
    "            data_[0].append(data[1][i])\n",
    "        else:\n",
    "            data_[1].append(data[1][i])\n",
    "\n",
    "    len_ = min(len(data_[1]), len(data_[0]))\n",
    "\n",
    "    data_[0] = data_[0][1:len_]\n",
    "    data_[1] = data_[1][1:len_]\n",
    "    return data_, len_ - 1\n",
    "\n",
    "\n",
    "class SpamData(Dataset):\n",
    "    def __init__(self, data_directory, train=True, rt=0.7):\n",
    "        self.data_, self.len_ = initData(data_directory)\n",
    "        mid = (int) (self.len_*rt)\n",
    "        if train:\n",
    "            self.data_[0] = self.data_[0][0:mid]\n",
    "            self.data_[1] = self.data_[1][0:mid]\n",
    "            self.len_ = mid\n",
    "        else:\n",
    "            self.data_[0] = self.data_[0][mid:]\n",
    "            self.data_[1] = self.data_[1][mid:]\n",
    "            self.len_ = self.len_ - mid\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len_ * 2\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if (index % 2 == 1):\n",
    "            return 1, self.data_[1][index % self.len_]\n",
    "        return 0, self.data_[0][index % self.len_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPositionEncoding(seq_len, d, n=10000):\n",
    "    P = torch.zeros((seq_len, d))\n",
    "    for k in range(seq_len):\n",
    "        for i in torch.arange(int(d/2)):\n",
    "            denominator = np.power(n, 2*i/d)\n",
    "            P[k, 2*i] = torch.sin(k/denominator)\n",
    "            P[k, 2*i+1] = torch.cos(k/denominator)\n",
    "    return P\n",
    "\n",
    "class Transmodel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Transmodel, self).__init__()\n",
    "        embed_dim = 48\n",
    "        self.embed = nn.Embedding(len(words_map), embed_dim)\n",
    "        layer = nn.TransformerEncoderLayer(embed_dim, 4)\n",
    "        self.transen = nn.TransformerEncoder(layer, 4)\n",
    "        self.ln = nn.Linear(embed_dim * sentence_len, sentence_len)\n",
    "        self.lno = nn.Linear(sentence_len, 1)\n",
    "\n",
    "    def forward(self, input):\n",
    "        r = self.embed(input)\n",
    "        posem = getPositionEncoding(r.size()[-2], r.size()[-1])\n",
    "        r = r + posem\n",
    "        r = self.transen(r)\n",
    "        r = torch.reshape(r, (input.size()[0],-1))\n",
    "        r = self.ln(r)\n",
    "        r = self.lno(r)\n",
    "        return torch.sigmoid(r)\n",
    "\n",
    "class LSTMmodel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LSTMmodel, self).__init__()\n",
    "        self.embed = nn.Embedding(len(words_map), 32)\n",
    "        self.lstm = nn.LSTM(32, 64, 4, batch_first=True)\n",
    "        self.ln = nn.Linear(64, 1)\n",
    "        self.lno = nn.Linear(sentence_len, 1)\n",
    "\n",
    "    def forward(self, input):\n",
    "        r = self.embed(input)\n",
    "        r = self.lstm(r)[0]\n",
    "        r = self.ln(r)\n",
    "        r = torch.reshape(r, (input.size()[0],-1))\n",
    "        r = self.lno(r)\n",
    "        return torch.sigmoid(r)\n",
    "    \n",
    "def train(yrmodel='lstm', epochs=2, lr=0.0005, batch_size=16):\n",
    "    data = SpamData(data_dir, True, 1)\n",
    "    data_test = SpamData(data_dir, True, 1)\n",
    "\n",
    "    model = None\n",
    "\n",
    "    if yrmodel == \"lstm\":\n",
    "        model = LSTMmodel()\n",
    "    else:\n",
    "        model = Transmodel()\n",
    "    data_test_size = len(data_test)\n",
    "\n",
    "    dataloader = DataLoader(data, batch_size=batch_size, shuffle=True)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    criteria = torch.nn.BCELoss()\n",
    "\n",
    "    for i in range(epochs):\n",
    "        for out, inp in dataloader:\n",
    "            out = torch.reshape(out, (-1,1)).float()\n",
    "            pred = model(inp)\n",
    "            loss = criteria(pred, out)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        if i % 1 == 0:\n",
    "            prob = 0\n",
    "            for j in range(len(data_test)):\n",
    "                out, inp = data_test[j]\n",
    "                with torch.no_grad():\n",
    "                    inp = torch.reshape(inp, (1, -1))\n",
    "                    pred = model(inp)\n",
    "                    a = (model(inp)-0.5)*(out-0.5)\n",
    "                    if a >= 0:\n",
    "                        prob += 1\n",
    "            \n",
    "            print(f\"epoch {i}  acc: {prob * 1.0 / data_test_size}\")\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_22606/489611986.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[1][i] = [word for word in word_tokenize(data[1][i]) if word not in stop_words]\n",
      "/tmp/ipykernel_22606/489611986.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[1][i] = [words_map[word] for word in data[1][i]]\n",
      "/tmp/ipykernel_22606/489611986.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[1][i] = [0] * (sentence_len - len(data[1][i])) + data[1][i]\n",
      "/tmp/ipykernel_22606/489611986.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[1][i] = torch.tensor(data[1][i])\n",
      "/tmp/ipykernel_22606/489611986.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[1][i] = [word for word in word_tokenize(data[1][i]) if word not in stop_words]\n",
      "/tmp/ipykernel_22606/489611986.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[1][i] = [words_map[word] for word in data[1][i]]\n",
      "/tmp/ipykernel_22606/489611986.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[1][i] = [0] * (sentence_len - len(data[1][i])) + data[1][i]\n",
      "/tmp/ipykernel_22606/489611986.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[1][i] = torch.tensor(data[1][i])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  acc: 0.5\n",
      "epoch 1  acc: 0.5\n",
      "epoch 2  acc: 0.5\n",
      "epoch 3  acc: 0.5\n",
      "epoch 4  acc: 0.5\n",
      "epoch 5  acc: 0.5\n",
      "epoch 6  acc: 0.5\n",
      "epoch 7  acc: 0.5\n",
      "epoch 8  acc: 0.5\n",
      "epoch 9  acc: 0.5\n",
      "epoch 10  acc: 0.5\n",
      "epoch 11  acc: 0.5\n",
      "epoch 12  acc: 0.5\n",
      "epoch 13  acc: 0.5\n",
      "epoch 14  acc: 0.5\n",
      "epoch 15  acc: 0.5\n",
      "epoch 16  acc: 0.5\n",
      "epoch 17  acc: 0.5\n",
      "epoch 18  acc: 0.5\n",
      "epoch 19  acc: 0.5\n",
      "epoch 20  acc: 0.5\n",
      "epoch 21  acc: 0.5\n",
      "epoch 22  acc: 0.5\n",
      "epoch 23  acc: 0.5\n",
      "epoch 24  acc: 0.5\n",
      "epoch 25  acc: 0.5\n",
      "epoch 26  acc: 0.5\n",
      "epoch 27  acc: 0.5\n",
      "epoch 28  acc: 0.5\n",
      "epoch 29  acc: 0.5\n",
      "epoch 30  acc: 0.5\n",
      "epoch 31  acc: 0.5\n",
      "epoch 32  acc: 0.5\n",
      "epoch 33  acc: 0.5\n",
      "epoch 34  acc: 0.5\n",
      "epoch 35  acc: 0.5\n",
      "epoch 36  acc: 0.5\n",
      "epoch 37  acc: 0.5\n",
      "epoch 38  acc: 0.5\n",
      "epoch 39  acc: 0.5\n",
      "epoch 40  acc: 0.5\n",
      "epoch 41  acc: 0.5\n",
      "epoch 42  acc: 0.5\n",
      "epoch 43  acc: 0.5\n",
      "epoch 44  acc: 0.5\n",
      "epoch 45  acc: 0.5\n",
      "epoch 46  acc: 0.5\n",
      "epoch 47  acc: 0.5\n",
      "epoch 48  acc: 0.5\n",
      "epoch 49  acc: 0.5\n",
      "epoch 50  acc: 0.5\n",
      "epoch 51  acc: 0.5\n",
      "epoch 52  acc: 0.5\n",
      "epoch 53  acc: 0.5\n",
      "epoch 54  acc: 0.5\n",
      "epoch 55  acc: 0.5\n",
      "epoch 56  acc: 0.5\n",
      "epoch 57  acc: 0.5\n",
      "epoch 58  acc: 0.5714285714285714\n",
      "epoch 59  acc: 0.7142857142857143\n",
      "epoch 60  acc: 0.7857142857142857\n",
      "epoch 61  acc: 0.7857142857142857\n",
      "epoch 62  acc: 0.8571428571428571\n",
      "epoch 63  acc: 0.8571428571428571\n",
      "epoch 64  acc: 0.8571428571428571\n",
      "epoch 65  acc: 0.8571428571428571\n",
      "epoch 66  acc: 0.9285714285714286\n",
      "epoch 67  acc: 1.0\n",
      "epoch 68  acc: 0.8571428571428571\n",
      "epoch 69  acc: 0.8571428571428571\n",
      "epoch 70  acc: 0.7857142857142857\n",
      "epoch 71  acc: 0.7857142857142857\n",
      "epoch 72  acc: 0.7857142857142857\n",
      "epoch 73  acc: 0.7857142857142857\n",
      "epoch 74  acc: 0.7857142857142857\n",
      "epoch 75  acc: 0.7857142857142857\n",
      "epoch 76  acc: 0.7857142857142857\n",
      "epoch 77  acc: 0.7857142857142857\n",
      "epoch 78  acc: 0.7857142857142857\n",
      "epoch 79  acc: 0.7857142857142857\n",
      "epoch 80  acc: 0.7857142857142857\n",
      "epoch 81  acc: 0.7857142857142857\n",
      "epoch 82  acc: 0.7857142857142857\n",
      "epoch 83  acc: 0.8571428571428571\n",
      "epoch 84  acc: 0.8571428571428571\n",
      "epoch 85  acc: 1.0\n",
      "epoch 86  acc: 1.0\n",
      "epoch 87  acc: 1.0\n",
      "epoch 88  acc: 0.9285714285714286\n",
      "epoch 89  acc: 0.8571428571428571\n",
      "epoch 90  acc: 0.8571428571428571\n",
      "epoch 91  acc: 0.8571428571428571\n",
      "epoch 92  acc: 0.8571428571428571\n",
      "epoch 93  acc: 0.8571428571428571\n",
      "epoch 94  acc: 0.8571428571428571\n",
      "epoch 95  acc: 0.8571428571428571\n",
      "epoch 96  acc: 0.8571428571428571\n",
      "epoch 97  acc: 0.8571428571428571\n",
      "epoch 98  acc: 0.8571428571428571\n",
      "epoch 99  acc: 0.8571428571428571\n",
      "epoch 100  acc: 0.8571428571428571\n",
      "epoch 101  acc: 0.8571428571428571\n",
      "epoch 102  acc: 0.8571428571428571\n",
      "epoch 103  acc: 0.8571428571428571\n",
      "epoch 104  acc: 0.8571428571428571\n",
      "epoch 105  acc: 0.9285714285714286\n",
      "epoch 106  acc: 1.0\n",
      "epoch 107  acc: 1.0\n",
      "epoch 108  acc: 1.0\n",
      "epoch 109  acc: 1.0\n",
      "epoch 110  acc: 1.0\n",
      "epoch 111  acc: 1.0\n",
      "epoch 112  acc: 0.9285714285714286\n",
      "epoch 113  acc: 0.8571428571428571\n",
      "epoch 114  acc: 0.8571428571428571\n",
      "epoch 115  acc: 0.8571428571428571\n",
      "epoch 116  acc: 0.8571428571428571\n",
      "epoch 117  acc: 0.7857142857142857\n",
      "epoch 118  acc: 0.7857142857142857\n",
      "epoch 119  acc: 0.7857142857142857\n",
      "epoch 120  acc: 0.7857142857142857\n",
      "epoch 121  acc: 0.7857142857142857\n",
      "epoch 122  acc: 0.7857142857142857\n",
      "epoch 123  acc: 0.7857142857142857\n",
      "epoch 124  acc: 0.7857142857142857\n",
      "epoch 125  acc: 0.7857142857142857\n",
      "epoch 126  acc: 0.7857142857142857\n",
      "epoch 127  acc: 0.7857142857142857\n",
      "epoch 128  acc: 0.7857142857142857\n",
      "epoch 129  acc: 0.7857142857142857\n",
      "epoch 130  acc: 0.7857142857142857\n",
      "epoch 131  acc: 0.7857142857142857\n",
      "epoch 132  acc: 0.8571428571428571\n",
      "epoch 133  acc: 0.8571428571428571\n",
      "epoch 134  acc: 0.8571428571428571\n",
      "epoch 135  acc: 0.8571428571428571\n",
      "epoch 136  acc: 0.8571428571428571\n",
      "epoch 137  acc: 0.8571428571428571\n",
      "epoch 138  acc: 0.8571428571428571\n",
      "epoch 139  acc: 0.9285714285714286\n",
      "epoch 140  acc: 0.9285714285714286\n",
      "epoch 141  acc: 0.9285714285714286\n",
      "epoch 142  acc: 0.9285714285714286\n",
      "epoch 143  acc: 1.0\n",
      "epoch 144  acc: 1.0\n",
      "epoch 145  acc: 1.0\n",
      "epoch 146  acc: 1.0\n",
      "epoch 147  acc: 1.0\n",
      "epoch 148  acc: 1.0\n",
      "epoch 149  acc: 1.0\n",
      "epoch 150  acc: 1.0\n",
      "epoch 151  acc: 1.0\n",
      "epoch 152  acc: 1.0\n",
      "epoch 153  acc: 1.0\n",
      "epoch 154  acc: 1.0\n",
      "epoch 155  acc: 1.0\n",
      "epoch 156  acc: 1.0\n",
      "epoch 157  acc: 1.0\n",
      "epoch 158  acc: 0.9285714285714286\n",
      "epoch 159  acc: 0.9285714285714286\n",
      "epoch 160  acc: 0.9285714285714286\n",
      "epoch 161  acc: 0.9285714285714286\n",
      "epoch 162  acc: 0.8571428571428571\n",
      "epoch 163  acc: 0.7142857142857143\n",
      "epoch 164  acc: 0.7142857142857143\n",
      "epoch 165  acc: 0.7142857142857143\n",
      "epoch 166  acc: 0.7142857142857143\n",
      "epoch 167  acc: 0.7142857142857143\n",
      "epoch 168  acc: 0.7142857142857143\n",
      "epoch 169  acc: 0.7142857142857143\n",
      "epoch 170  acc: 0.7142857142857143\n",
      "epoch 171  acc: 0.7857142857142857\n",
      "epoch 172  acc: 0.7857142857142857\n",
      "epoch 173  acc: 0.8571428571428571\n",
      "epoch 174  acc: 0.8571428571428571\n",
      "epoch 175  acc: 0.8571428571428571\n",
      "epoch 176  acc: 0.8571428571428571\n",
      "epoch 177  acc: 0.9285714285714286\n",
      "epoch 178  acc: 1.0\n",
      "epoch 179  acc: 1.0\n",
      "epoch 180  acc: 1.0\n",
      "epoch 181  acc: 1.0\n",
      "epoch 182  acc: 1.0\n",
      "epoch 183  acc: 1.0\n",
      "epoch 184  acc: 1.0\n",
      "epoch 185  acc: 1.0\n",
      "epoch 186  acc: 1.0\n",
      "epoch 187  acc: 1.0\n",
      "epoch 188  acc: 1.0\n",
      "epoch 189  acc: 1.0\n",
      "epoch 190  acc: 1.0\n",
      "epoch 191  acc: 1.0\n",
      "epoch 192  acc: 1.0\n",
      "epoch 193  acc: 1.0\n",
      "epoch 194  acc: 1.0\n",
      "epoch 195  acc: 1.0\n",
      "epoch 196  acc: 1.0\n",
      "epoch 197  acc: 1.0\n",
      "epoch 198  acc: 1.0\n",
      "epoch 199  acc: 1.0\n",
      "epoch 200  acc: 1.0\n",
      "epoch 201  acc: 1.0\n",
      "epoch 202  acc: 1.0\n",
      "epoch 203  acc: 1.0\n",
      "epoch 204  acc: 1.0\n",
      "epoch 205  acc: 1.0\n",
      "epoch 206  acc: 1.0\n",
      "epoch 207  acc: 1.0\n",
      "epoch 208  acc: 1.0\n",
      "epoch 209  acc: 1.0\n",
      "epoch 210  acc: 1.0\n",
      "epoch 211  acc: 1.0\n",
      "epoch 212  acc: 1.0\n",
      "epoch 213  acc: 1.0\n",
      "epoch 214  acc: 1.0\n",
      "epoch 215  acc: 1.0\n",
      "epoch 216  acc: 1.0\n",
      "epoch 217  acc: 1.0\n",
      "epoch 218  acc: 1.0\n",
      "epoch 219  acc: 1.0\n",
      "epoch 220  acc: 1.0\n",
      "epoch 221  acc: 1.0\n",
      "epoch 222  acc: 1.0\n",
      "epoch 223  acc: 1.0\n",
      "epoch 224  acc: 1.0\n",
      "epoch 225  acc: 1.0\n",
      "epoch 226  acc: 0.9285714285714286\n",
      "epoch 227  acc: 0.9285714285714286\n",
      "epoch 228  acc: 0.9285714285714286\n",
      "epoch 229  acc: 0.9285714285714286\n",
      "epoch 230  acc: 0.9285714285714286\n",
      "epoch 231  acc: 0.9285714285714286\n",
      "epoch 232  acc: 0.9285714285714286\n",
      "epoch 233  acc: 0.9285714285714286\n",
      "epoch 234  acc: 0.9285714285714286\n",
      "epoch 235  acc: 0.9285714285714286\n",
      "epoch 236  acc: 0.9285714285714286\n",
      "epoch 237  acc: 0.9285714285714286\n",
      "epoch 238  acc: 0.9285714285714286\n",
      "epoch 239  acc: 0.9285714285714286\n",
      "epoch 240  acc: 0.9285714285714286\n",
      "epoch 241  acc: 0.9285714285714286\n",
      "epoch 242  acc: 0.9285714285714286\n",
      "epoch 243  acc: 0.9285714285714286\n",
      "epoch 244  acc: 0.9285714285714286\n",
      "epoch 245  acc: 0.9285714285714286\n",
      "epoch 246  acc: 0.9285714285714286\n",
      "epoch 247  acc: 0.9285714285714286\n",
      "epoch 248  acc: 0.9285714285714286\n",
      "epoch 249  acc: 1.0\n",
      "epoch 250  acc: 1.0\n",
      "epoch 251  acc: 1.0\n",
      "epoch 252  acc: 1.0\n",
      "epoch 253  acc: 1.0\n",
      "epoch 254  acc: 1.0\n",
      "epoch 255  acc: 1.0\n",
      "epoch 256  acc: 1.0\n",
      "epoch 257  acc: 1.0\n",
      "epoch 258  acc: 1.0\n",
      "epoch 259  acc: 1.0\n",
      "epoch 260  acc: 1.0\n",
      "epoch 261  acc: 1.0\n",
      "epoch 262  acc: 1.0\n",
      "epoch 263  acc: 1.0\n",
      "epoch 264  acc: 1.0\n",
      "epoch 265  acc: 1.0\n",
      "epoch 266  acc: 1.0\n",
      "epoch 267  acc: 1.0\n",
      "epoch 268  acc: 1.0\n",
      "epoch 269  acc: 1.0\n",
      "epoch 270  acc: 1.0\n",
      "epoch 271  acc: 1.0\n",
      "epoch 272  acc: 1.0\n",
      "epoch 273  acc: 1.0\n",
      "epoch 274  acc: 1.0\n",
      "epoch 275  acc: 1.0\n",
      "epoch 276  acc: 1.0\n",
      "epoch 277  acc: 1.0\n",
      "epoch 278  acc: 1.0\n",
      "epoch 279  acc: 1.0\n",
      "epoch 280  acc: 1.0\n",
      "epoch 281  acc: 1.0\n",
      "epoch 282  acc: 1.0\n",
      "epoch 283  acc: 1.0\n",
      "epoch 284  acc: 1.0\n",
      "epoch 285  acc: 1.0\n",
      "epoch 286  acc: 1.0\n",
      "epoch 287  acc: 1.0\n",
      "epoch 288  acc: 1.0\n",
      "epoch 289  acc: 1.0\n",
      "epoch 290  acc: 1.0\n",
      "epoch 291  acc: 1.0\n",
      "epoch 292  acc: 1.0\n",
      "epoch 293  acc: 1.0\n",
      "epoch 294  acc: 1.0\n",
      "epoch 295  acc: 1.0\n",
      "epoch 296  acc: 1.0\n",
      "epoch 297  acc: 1.0\n",
      "epoch 298  acc: 1.0\n",
      "epoch 299  acc: 1.0\n",
      "epoch 300  acc: 1.0\n",
      "epoch 301  acc: 1.0\n",
      "epoch 302  acc: 1.0\n",
      "epoch 303  acc: 1.0\n",
      "epoch 304  acc: 1.0\n",
      "epoch 305  acc: 1.0\n",
      "epoch 306  acc: 1.0\n",
      "epoch 307  acc: 1.0\n",
      "epoch 308  acc: 1.0\n",
      "epoch 309  acc: 1.0\n",
      "epoch 310  acc: 1.0\n",
      "epoch 311  acc: 1.0\n",
      "epoch 312  acc: 1.0\n",
      "epoch 313  acc: 1.0\n",
      "epoch 314  acc: 1.0\n",
      "epoch 315  acc: 1.0\n",
      "epoch 316  acc: 1.0\n",
      "epoch 317  acc: 1.0\n",
      "epoch 318  acc: 1.0\n",
      "epoch 319  acc: 1.0\n",
      "epoch 320  acc: 1.0\n",
      "epoch 321  acc: 1.0\n",
      "epoch 322  acc: 1.0\n",
      "epoch 323  acc: 1.0\n",
      "epoch 324  acc: 1.0\n",
      "epoch 325  acc: 1.0\n",
      "epoch 326  acc: 1.0\n",
      "epoch 327  acc: 1.0\n",
      "epoch 328  acc: 1.0\n",
      "epoch 329  acc: 1.0\n",
      "epoch 330  acc: 1.0\n",
      "epoch 331  acc: 1.0\n",
      "epoch 332  acc: 1.0\n",
      "epoch 333  acc: 1.0\n",
      "epoch 334  acc: 1.0\n",
      "epoch 335  acc: 1.0\n",
      "epoch 336  acc: 1.0\n",
      "epoch 337  acc: 1.0\n",
      "epoch 338  acc: 1.0\n",
      "epoch 339  acc: 1.0\n",
      "epoch 340  acc: 1.0\n",
      "epoch 341  acc: 1.0\n",
      "epoch 342  acc: 1.0\n",
      "epoch 343  acc: 1.0\n",
      "epoch 344  acc: 1.0\n",
      "epoch 345  acc: 1.0\n",
      "epoch 346  acc: 1.0\n",
      "epoch 347  acc: 1.0\n",
      "epoch 348  acc: 1.0\n",
      "epoch 349  acc: 1.0\n",
      "epoch 350  acc: 1.0\n",
      "epoch 351  acc: 1.0\n",
      "epoch 352  acc: 1.0\n",
      "epoch 353  acc: 1.0\n",
      "epoch 354  acc: 1.0\n",
      "epoch 355  acc: 1.0\n",
      "epoch 356  acc: 1.0\n",
      "epoch 357  acc: 1.0\n",
      "epoch 358  acc: 1.0\n",
      "epoch 359  acc: 1.0\n",
      "epoch 360  acc: 1.0\n",
      "epoch 361  acc: 1.0\n",
      "epoch 362  acc: 1.0\n",
      "epoch 363  acc: 1.0\n",
      "epoch 364  acc: 1.0\n",
      "epoch 365  acc: 1.0\n",
      "epoch 366  acc: 1.0\n",
      "epoch 367  acc: 1.0\n",
      "epoch 368  acc: 1.0\n",
      "epoch 369  acc: 1.0\n",
      "epoch 370  acc: 1.0\n",
      "epoch 371  acc: 1.0\n",
      "epoch 372  acc: 1.0\n",
      "epoch 373  acc: 1.0\n",
      "epoch 374  acc: 1.0\n",
      "epoch 375  acc: 1.0\n",
      "epoch 376  acc: 1.0\n",
      "epoch 377  acc: 1.0\n",
      "epoch 378  acc: 1.0\n",
      "epoch 379  acc: 1.0\n",
      "epoch 380  acc: 1.0\n",
      "epoch 381  acc: 1.0\n",
      "epoch 382  acc: 1.0\n",
      "epoch 383  acc: 1.0\n",
      "epoch 384  acc: 1.0\n",
      "epoch 385  acc: 1.0\n",
      "epoch 386  acc: 1.0\n",
      "epoch 387  acc: 1.0\n",
      "epoch 388  acc: 1.0\n",
      "epoch 389  acc: 1.0\n",
      "epoch 390  acc: 1.0\n",
      "epoch 391  acc: 1.0\n",
      "epoch 392  acc: 1.0\n",
      "epoch 393  acc: 1.0\n",
      "epoch 394  acc: 1.0\n",
      "epoch 395  acc: 1.0\n",
      "epoch 396  acc: 1.0\n",
      "epoch 397  acc: 1.0\n",
      "epoch 398  acc: 1.0\n",
      "epoch 399  acc: 1.0\n",
      "epoch 400  acc: 1.0\n",
      "epoch 401  acc: 1.0\n",
      "epoch 402  acc: 1.0\n",
      "epoch 403  acc: 1.0\n",
      "epoch 404  acc: 1.0\n",
      "epoch 405  acc: 1.0\n",
      "epoch 406  acc: 1.0\n",
      "epoch 407  acc: 1.0\n",
      "epoch 408  acc: 1.0\n",
      "epoch 409  acc: 1.0\n",
      "epoch 410  acc: 1.0\n",
      "epoch 411  acc: 1.0\n",
      "epoch 412  acc: 1.0\n",
      "epoch 413  acc: 1.0\n",
      "epoch 414  acc: 1.0\n",
      "epoch 415  acc: 1.0\n",
      "epoch 416  acc: 1.0\n",
      "epoch 417  acc: 1.0\n",
      "epoch 418  acc: 1.0\n",
      "epoch 419  acc: 1.0\n",
      "epoch 420  acc: 1.0\n",
      "epoch 421  acc: 1.0\n",
      "epoch 422  acc: 1.0\n",
      "epoch 423  acc: 1.0\n",
      "epoch 424  acc: 1.0\n",
      "epoch 425  acc: 1.0\n",
      "epoch 426  acc: 1.0\n",
      "epoch 427  acc: 1.0\n",
      "epoch 428  acc: 1.0\n",
      "epoch 429  acc: 1.0\n",
      "epoch 430  acc: 1.0\n",
      "epoch 431  acc: 1.0\n",
      "epoch 432  acc: 1.0\n",
      "epoch 433  acc: 1.0\n",
      "epoch 434  acc: 1.0\n",
      "epoch 435  acc: 1.0\n",
      "epoch 436  acc: 1.0\n",
      "epoch 437  acc: 1.0\n",
      "epoch 438  acc: 1.0\n",
      "epoch 439  acc: 1.0\n",
      "epoch 440  acc: 1.0\n",
      "epoch 441  acc: 1.0\n",
      "epoch 442  acc: 1.0\n",
      "epoch 443  acc: 1.0\n",
      "epoch 444  acc: 1.0\n",
      "epoch 445  acc: 1.0\n",
      "epoch 446  acc: 1.0\n",
      "epoch 447  acc: 1.0\n",
      "epoch 448  acc: 1.0\n",
      "epoch 449  acc: 1.0\n",
      "epoch 450  acc: 1.0\n",
      "epoch 451  acc: 1.0\n",
      "epoch 452  acc: 1.0\n",
      "epoch 453  acc: 1.0\n",
      "epoch 454  acc: 1.0\n",
      "epoch 455  acc: 1.0\n",
      "epoch 456  acc: 1.0\n",
      "epoch 457  acc: 1.0\n",
      "epoch 458  acc: 1.0\n",
      "epoch 459  acc: 1.0\n",
      "epoch 460  acc: 1.0\n",
      "epoch 461  acc: 1.0\n",
      "epoch 462  acc: 1.0\n",
      "epoch 463  acc: 1.0\n",
      "epoch 464  acc: 1.0\n",
      "epoch 465  acc: 1.0\n",
      "epoch 466  acc: 1.0\n",
      "epoch 467  acc: 1.0\n",
      "epoch 468  acc: 1.0\n",
      "epoch 469  acc: 1.0\n",
      "epoch 470  acc: 1.0\n",
      "epoch 471  acc: 1.0\n",
      "epoch 472  acc: 1.0\n",
      "epoch 473  acc: 1.0\n",
      "epoch 474  acc: 1.0\n",
      "epoch 475  acc: 1.0\n",
      "epoch 476  acc: 1.0\n",
      "epoch 477  acc: 1.0\n",
      "epoch 478  acc: 1.0\n",
      "epoch 479  acc: 1.0\n",
      "epoch 480  acc: 1.0\n",
      "epoch 481  acc: 1.0\n",
      "epoch 482  acc: 1.0\n",
      "epoch 483  acc: 1.0\n",
      "epoch 484  acc: 1.0\n",
      "epoch 485  acc: 1.0\n",
      "epoch 486  acc: 1.0\n",
      "epoch 487  acc: 1.0\n",
      "epoch 488  acc: 1.0\n",
      "epoch 489  acc: 1.0\n",
      "epoch 490  acc: 1.0\n",
      "epoch 491  acc: 1.0\n",
      "epoch 492  acc: 1.0\n",
      "epoch 493  acc: 1.0\n",
      "epoch 494  acc: 1.0\n",
      "epoch 495  acc: 1.0\n",
      "epoch 496  acc: 1.0\n",
      "epoch 497  acc: 1.0\n",
      "epoch 498  acc: 1.0\n",
      "epoch 499  acc: 1.0\n",
      "epoch 500  acc: 1.0\n",
      "epoch 501  acc: 1.0\n",
      "epoch 502  acc: 1.0\n",
      "epoch 503  acc: 1.0\n",
      "epoch 504  acc: 1.0\n",
      "epoch 505  acc: 1.0\n",
      "epoch 506  acc: 1.0\n",
      "epoch 507  acc: 1.0\n",
      "epoch 508  acc: 1.0\n",
      "epoch 509  acc: 1.0\n",
      "epoch 510  acc: 1.0\n",
      "epoch 511  acc: 1.0\n",
      "epoch 512  acc: 1.0\n",
      "epoch 513  acc: 1.0\n",
      "epoch 514  acc: 1.0\n",
      "epoch 515  acc: 1.0\n",
      "epoch 516  acc: 1.0\n",
      "epoch 517  acc: 1.0\n",
      "epoch 518  acc: 1.0\n",
      "epoch 519  acc: 1.0\n",
      "epoch 520  acc: 1.0\n",
      "epoch 521  acc: 1.0\n",
      "epoch 522  acc: 1.0\n",
      "epoch 523  acc: 1.0\n",
      "epoch 524  acc: 1.0\n",
      "epoch 525  acc: 1.0\n",
      "epoch 526  acc: 1.0\n",
      "epoch 527  acc: 1.0\n",
      "epoch 528  acc: 1.0\n",
      "epoch 529  acc: 1.0\n",
      "epoch 530  acc: 1.0\n",
      "epoch 531  acc: 1.0\n",
      "epoch 532  acc: 1.0\n",
      "epoch 533  acc: 1.0\n",
      "epoch 534  acc: 1.0\n",
      "epoch 535  acc: 1.0\n",
      "epoch 536  acc: 1.0\n",
      "epoch 537  acc: 1.0\n",
      "epoch 538  acc: 1.0\n",
      "epoch 539  acc: 1.0\n",
      "epoch 540  acc: 1.0\n",
      "epoch 541  acc: 1.0\n",
      "epoch 542  acc: 1.0\n",
      "epoch 543  acc: 1.0\n",
      "epoch 544  acc: 1.0\n",
      "epoch 545  acc: 1.0\n",
      "epoch 546  acc: 1.0\n",
      "epoch 547  acc: 1.0\n",
      "epoch 548  acc: 1.0\n",
      "epoch 549  acc: 1.0\n",
      "epoch 550  acc: 1.0\n",
      "epoch 551  acc: 1.0\n",
      "epoch 552  acc: 1.0\n",
      "epoch 553  acc: 1.0\n",
      "epoch 554  acc: 1.0\n",
      "epoch 555  acc: 1.0\n",
      "epoch 556  acc: 1.0\n",
      "epoch 557  acc: 1.0\n",
      "epoch 558  acc: 1.0\n",
      "epoch 559  acc: 1.0\n",
      "epoch 560  acc: 1.0\n",
      "epoch 561  acc: 1.0\n",
      "epoch 562  acc: 1.0\n",
      "epoch 563  acc: 1.0\n",
      "epoch 564  acc: 1.0\n",
      "epoch 565  acc: 1.0\n",
      "epoch 566  acc: 1.0\n",
      "epoch 567  acc: 1.0\n",
      "epoch 568  acc: 1.0\n",
      "epoch 569  acc: 1.0\n",
      "epoch 570  acc: 1.0\n",
      "epoch 571  acc: 1.0\n",
      "epoch 572  acc: 1.0\n",
      "epoch 573  acc: 1.0\n",
      "epoch 574  acc: 1.0\n",
      "epoch 575  acc: 1.0\n",
      "epoch 576  acc: 1.0\n",
      "epoch 577  acc: 1.0\n",
      "epoch 578  acc: 1.0\n",
      "epoch 579  acc: 1.0\n",
      "epoch 580  acc: 1.0\n",
      "epoch 581  acc: 1.0\n",
      "epoch 582  acc: 1.0\n",
      "epoch 583  acc: 1.0\n",
      "epoch 584  acc: 1.0\n",
      "epoch 585  acc: 1.0\n",
      "epoch 586  acc: 1.0\n",
      "epoch 587  acc: 1.0\n",
      "epoch 588  acc: 1.0\n",
      "epoch 589  acc: 1.0\n",
      "epoch 590  acc: 1.0\n",
      "epoch 591  acc: 1.0\n",
      "epoch 592  acc: 1.0\n",
      "epoch 593  acc: 1.0\n",
      "epoch 594  acc: 1.0\n",
      "epoch 595  acc: 1.0\n",
      "epoch 596  acc: 1.0\n",
      "epoch 597  acc: 1.0\n",
      "epoch 598  acc: 1.0\n",
      "epoch 599  acc: 1.0\n",
      "epoch 600  acc: 1.0\n",
      "epoch 601  acc: 1.0\n",
      "epoch 602  acc: 1.0\n",
      "epoch 603  acc: 1.0\n",
      "epoch 604  acc: 1.0\n",
      "epoch 605  acc: 1.0\n",
      "epoch 606  acc: 1.0\n",
      "epoch 607  acc: 1.0\n",
      "epoch 608  acc: 1.0\n",
      "epoch 609  acc: 1.0\n",
      "epoch 610  acc: 1.0\n",
      "epoch 611  acc: 1.0\n",
      "epoch 612  acc: 1.0\n",
      "epoch 613  acc: 1.0\n",
      "epoch 614  acc: 1.0\n",
      "epoch 615  acc: 1.0\n",
      "epoch 616  acc: 1.0\n",
      "epoch 617  acc: 1.0\n",
      "epoch 618  acc: 1.0\n",
      "epoch 619  acc: 1.0\n",
      "epoch 620  acc: 1.0\n",
      "epoch 621  acc: 1.0\n",
      "epoch 622  acc: 1.0\n",
      "epoch 623  acc: 1.0\n",
      "epoch 624  acc: 1.0\n",
      "epoch 625  acc: 1.0\n",
      "epoch 626  acc: 1.0\n",
      "epoch 627  acc: 1.0\n",
      "epoch 628  acc: 1.0\n",
      "epoch 629  acc: 1.0\n",
      "epoch 630  acc: 1.0\n",
      "epoch 631  acc: 1.0\n",
      "epoch 632  acc: 1.0\n",
      "epoch 633  acc: 1.0\n",
      "epoch 634  acc: 1.0\n",
      "epoch 635  acc: 1.0\n",
      "epoch 636  acc: 1.0\n",
      "epoch 637  acc: 1.0\n",
      "epoch 638  acc: 1.0\n",
      "epoch 639  acc: 1.0\n",
      "epoch 640  acc: 1.0\n",
      "epoch 641  acc: 1.0\n",
      "epoch 642  acc: 1.0\n",
      "epoch 643  acc: 1.0\n",
      "epoch 644  acc: 1.0\n",
      "epoch 645  acc: 1.0\n",
      "epoch 646  acc: 1.0\n",
      "epoch 647  acc: 1.0\n",
      "epoch 648  acc: 1.0\n",
      "epoch 649  acc: 1.0\n",
      "epoch 650  acc: 1.0\n",
      "epoch 651  acc: 1.0\n",
      "epoch 652  acc: 1.0\n",
      "epoch 653  acc: 1.0\n",
      "epoch 654  acc: 1.0\n",
      "epoch 655  acc: 1.0\n",
      "epoch 656  acc: 1.0\n",
      "epoch 657  acc: 1.0\n",
      "epoch 658  acc: 1.0\n",
      "epoch 659  acc: 1.0\n",
      "epoch 660  acc: 1.0\n",
      "epoch 661  acc: 1.0\n",
      "epoch 662  acc: 1.0\n",
      "epoch 663  acc: 1.0\n",
      "epoch 664  acc: 1.0\n",
      "epoch 665  acc: 1.0\n",
      "epoch 666  acc: 1.0\n",
      "epoch 667  acc: 1.0\n",
      "epoch 668  acc: 1.0\n",
      "epoch 669  acc: 1.0\n",
      "epoch 670  acc: 1.0\n",
      "epoch 671  acc: 1.0\n",
      "epoch 672  acc: 1.0\n",
      "epoch 673  acc: 1.0\n",
      "epoch 674  acc: 1.0\n",
      "epoch 675  acc: 1.0\n",
      "epoch 676  acc: 1.0\n",
      "epoch 677  acc: 1.0\n",
      "epoch 678  acc: 1.0\n",
      "epoch 679  acc: 1.0\n",
      "epoch 680  acc: 1.0\n",
      "epoch 681  acc: 1.0\n",
      "epoch 682  acc: 1.0\n",
      "epoch 683  acc: 1.0\n",
      "epoch 684  acc: 1.0\n",
      "epoch 685  acc: 1.0\n",
      "epoch 686  acc: 1.0\n",
      "epoch 687  acc: 1.0\n",
      "epoch 688  acc: 1.0\n",
      "epoch 689  acc: 1.0\n",
      "epoch 690  acc: 1.0\n",
      "epoch 691  acc: 1.0\n",
      "epoch 692  acc: 1.0\n",
      "epoch 693  acc: 1.0\n",
      "epoch 694  acc: 1.0\n",
      "epoch 695  acc: 1.0\n",
      "epoch 696  acc: 1.0\n",
      "epoch 697  acc: 1.0\n",
      "epoch 698  acc: 1.0\n",
      "epoch 699  acc: 1.0\n",
      "epoch 700  acc: 1.0\n",
      "epoch 701  acc: 1.0\n",
      "epoch 702  acc: 1.0\n",
      "epoch 703  acc: 1.0\n",
      "epoch 704  acc: 1.0\n",
      "epoch 705  acc: 1.0\n",
      "epoch 706  acc: 1.0\n",
      "epoch 707  acc: 1.0\n",
      "epoch 708  acc: 1.0\n",
      "epoch 709  acc: 1.0\n",
      "epoch 710  acc: 1.0\n",
      "epoch 711  acc: 1.0\n",
      "epoch 712  acc: 1.0\n",
      "epoch 713  acc: 1.0\n",
      "epoch 714  acc: 1.0\n",
      "epoch 715  acc: 1.0\n",
      "epoch 716  acc: 1.0\n",
      "epoch 717  acc: 1.0\n",
      "epoch 718  acc: 1.0\n",
      "epoch 719  acc: 1.0\n",
      "epoch 720  acc: 1.0\n",
      "epoch 721  acc: 1.0\n",
      "epoch 722  acc: 1.0\n",
      "epoch 723  acc: 1.0\n",
      "epoch 724  acc: 1.0\n",
      "epoch 725  acc: 1.0\n",
      "epoch 726  acc: 1.0\n",
      "epoch 727  acc: 1.0\n",
      "epoch 728  acc: 1.0\n",
      "epoch 729  acc: 1.0\n",
      "epoch 730  acc: 1.0\n",
      "epoch 731  acc: 1.0\n",
      "epoch 732  acc: 1.0\n",
      "epoch 733  acc: 1.0\n",
      "epoch 734  acc: 1.0\n",
      "epoch 735  acc: 1.0\n",
      "epoch 736  acc: 1.0\n",
      "epoch 737  acc: 1.0\n",
      "epoch 738  acc: 1.0\n",
      "epoch 739  acc: 1.0\n",
      "epoch 740  acc: 1.0\n",
      "epoch 741  acc: 1.0\n",
      "epoch 742  acc: 1.0\n",
      "epoch 743  acc: 1.0\n",
      "epoch 744  acc: 1.0\n",
      "epoch 745  acc: 1.0\n",
      "epoch 746  acc: 1.0\n",
      "epoch 747  acc: 1.0\n",
      "epoch 748  acc: 1.0\n",
      "epoch 749  acc: 1.0\n",
      "epoch 750  acc: 1.0\n",
      "epoch 751  acc: 1.0\n",
      "epoch 752  acc: 1.0\n",
      "epoch 753  acc: 1.0\n",
      "epoch 754  acc: 1.0\n",
      "epoch 755  acc: 1.0\n",
      "epoch 756  acc: 1.0\n",
      "epoch 757  acc: 1.0\n",
      "epoch 758  acc: 1.0\n",
      "epoch 759  acc: 1.0\n",
      "epoch 760  acc: 1.0\n",
      "epoch 761  acc: 1.0\n",
      "epoch 762  acc: 1.0\n",
      "epoch 763  acc: 1.0\n",
      "epoch 764  acc: 1.0\n",
      "epoch 765  acc: 1.0\n",
      "epoch 766  acc: 1.0\n",
      "epoch 767  acc: 1.0\n",
      "epoch 768  acc: 1.0\n",
      "epoch 769  acc: 1.0\n",
      "epoch 770  acc: 1.0\n",
      "epoch 771  acc: 1.0\n",
      "epoch 772  acc: 1.0\n",
      "epoch 773  acc: 1.0\n",
      "epoch 774  acc: 1.0\n",
      "epoch 775  acc: 1.0\n",
      "epoch 776  acc: 1.0\n",
      "epoch 777  acc: 1.0\n",
      "epoch 778  acc: 1.0\n",
      "epoch 779  acc: 1.0\n",
      "epoch 780  acc: 1.0\n",
      "epoch 781  acc: 1.0\n",
      "epoch 782  acc: 1.0\n",
      "epoch 783  acc: 1.0\n",
      "epoch 784  acc: 1.0\n",
      "epoch 785  acc: 1.0\n",
      "epoch 786  acc: 1.0\n",
      "epoch 787  acc: 1.0\n",
      "epoch 788  acc: 1.0\n",
      "epoch 789  acc: 1.0\n",
      "epoch 790  acc: 1.0\n",
      "epoch 791  acc: 1.0\n",
      "epoch 792  acc: 1.0\n",
      "epoch 793  acc: 1.0\n",
      "epoch 794  acc: 1.0\n",
      "epoch 795  acc: 1.0\n",
      "epoch 796  acc: 1.0\n",
      "epoch 797  acc: 1.0\n",
      "epoch 798  acc: 1.0\n",
      "epoch 799  acc: 1.0\n",
      "epoch 800  acc: 1.0\n",
      "epoch 801  acc: 1.0\n",
      "epoch 802  acc: 1.0\n",
      "epoch 803  acc: 1.0\n",
      "epoch 804  acc: 1.0\n",
      "epoch 805  acc: 1.0\n",
      "epoch 806  acc: 1.0\n",
      "epoch 807  acc: 1.0\n",
      "epoch 808  acc: 1.0\n",
      "epoch 809  acc: 1.0\n",
      "epoch 810  acc: 1.0\n",
      "epoch 811  acc: 1.0\n",
      "epoch 812  acc: 1.0\n",
      "epoch 813  acc: 1.0\n",
      "epoch 814  acc: 1.0\n",
      "epoch 815  acc: 1.0\n",
      "epoch 816  acc: 1.0\n",
      "epoch 817  acc: 1.0\n",
      "epoch 818  acc: 1.0\n",
      "epoch 819  acc: 1.0\n",
      "epoch 820  acc: 1.0\n",
      "epoch 821  acc: 1.0\n",
      "epoch 822  acc: 1.0\n",
      "epoch 823  acc: 1.0\n",
      "epoch 824  acc: 1.0\n",
      "epoch 825  acc: 1.0\n",
      "epoch 826  acc: 1.0\n",
      "epoch 827  acc: 1.0\n",
      "epoch 828  acc: 1.0\n",
      "epoch 829  acc: 1.0\n",
      "epoch 830  acc: 1.0\n",
      "epoch 831  acc: 1.0\n",
      "epoch 832  acc: 1.0\n",
      "epoch 833  acc: 1.0\n",
      "epoch 834  acc: 1.0\n",
      "epoch 835  acc: 1.0\n",
      "epoch 836  acc: 1.0\n",
      "epoch 837  acc: 1.0\n",
      "epoch 838  acc: 1.0\n",
      "epoch 839  acc: 1.0\n",
      "epoch 840  acc: 1.0\n",
      "epoch 841  acc: 1.0\n",
      "epoch 842  acc: 1.0\n",
      "epoch 843  acc: 1.0\n",
      "epoch 844  acc: 1.0\n",
      "epoch 845  acc: 1.0\n",
      "epoch 846  acc: 1.0\n",
      "epoch 847  acc: 1.0\n",
      "epoch 848  acc: 1.0\n",
      "epoch 849  acc: 1.0\n",
      "epoch 850  acc: 1.0\n",
      "epoch 851  acc: 1.0\n",
      "epoch 852  acc: 1.0\n",
      "epoch 853  acc: 1.0\n",
      "epoch 854  acc: 1.0\n",
      "epoch 855  acc: 1.0\n",
      "epoch 856  acc: 1.0\n",
      "epoch 857  acc: 1.0\n",
      "epoch 858  acc: 1.0\n",
      "epoch 859  acc: 1.0\n",
      "epoch 860  acc: 1.0\n",
      "epoch 861  acc: 1.0\n",
      "epoch 862  acc: 1.0\n",
      "epoch 863  acc: 1.0\n",
      "epoch 864  acc: 1.0\n",
      "epoch 865  acc: 1.0\n",
      "epoch 866  acc: 1.0\n",
      "epoch 867  acc: 1.0\n",
      "epoch 868  acc: 1.0\n",
      "epoch 869  acc: 1.0\n",
      "epoch 870  acc: 1.0\n",
      "epoch 871  acc: 1.0\n",
      "epoch 872  acc: 1.0\n",
      "epoch 873  acc: 1.0\n",
      "epoch 874  acc: 1.0\n",
      "epoch 875  acc: 1.0\n",
      "epoch 876  acc: 1.0\n",
      "epoch 877  acc: 1.0\n",
      "epoch 878  acc: 1.0\n",
      "epoch 879  acc: 1.0\n",
      "epoch 880  acc: 1.0\n",
      "epoch 881  acc: 1.0\n",
      "epoch 882  acc: 1.0\n",
      "epoch 883  acc: 1.0\n",
      "epoch 884  acc: 1.0\n",
      "epoch 885  acc: 1.0\n",
      "epoch 886  acc: 1.0\n",
      "epoch 887  acc: 1.0\n",
      "epoch 888  acc: 1.0\n",
      "epoch 889  acc: 1.0\n",
      "epoch 890  acc: 1.0\n",
      "epoch 891  acc: 1.0\n",
      "epoch 892  acc: 1.0\n",
      "epoch 893  acc: 1.0\n",
      "epoch 894  acc: 1.0\n",
      "epoch 895  acc: 1.0\n",
      "epoch 896  acc: 1.0\n",
      "epoch 897  acc: 1.0\n",
      "epoch 898  acc: 1.0\n",
      "epoch 899  acc: 1.0\n",
      "epoch 900  acc: 1.0\n",
      "epoch 901  acc: 1.0\n",
      "epoch 902  acc: 1.0\n",
      "epoch 903  acc: 1.0\n",
      "epoch 904  acc: 1.0\n",
      "epoch 905  acc: 1.0\n",
      "epoch 906  acc: 1.0\n",
      "epoch 907  acc: 1.0\n",
      "epoch 908  acc: 1.0\n",
      "epoch 909  acc: 1.0\n",
      "epoch 910  acc: 1.0\n",
      "epoch 911  acc: 1.0\n",
      "epoch 912  acc: 1.0\n",
      "epoch 913  acc: 1.0\n",
      "epoch 914  acc: 1.0\n",
      "epoch 915  acc: 1.0\n",
      "epoch 916  acc: 1.0\n",
      "epoch 917  acc: 1.0\n",
      "epoch 918  acc: 1.0\n",
      "epoch 919  acc: 1.0\n",
      "epoch 920  acc: 1.0\n",
      "epoch 921  acc: 1.0\n",
      "epoch 922  acc: 1.0\n",
      "epoch 923  acc: 1.0\n",
      "epoch 924  acc: 1.0\n",
      "epoch 925  acc: 1.0\n",
      "epoch 926  acc: 1.0\n",
      "epoch 927  acc: 1.0\n",
      "epoch 928  acc: 1.0\n",
      "epoch 929  acc: 1.0\n",
      "epoch 930  acc: 1.0\n",
      "epoch 931  acc: 1.0\n",
      "epoch 932  acc: 1.0\n",
      "epoch 933  acc: 1.0\n",
      "epoch 934  acc: 1.0\n",
      "epoch 935  acc: 1.0\n",
      "epoch 936  acc: 1.0\n",
      "epoch 937  acc: 1.0\n",
      "epoch 938  acc: 1.0\n",
      "epoch 939  acc: 1.0\n",
      "epoch 940  acc: 1.0\n",
      "epoch 941  acc: 1.0\n",
      "epoch 942  acc: 1.0\n",
      "epoch 943  acc: 1.0\n",
      "epoch 944  acc: 1.0\n",
      "epoch 945  acc: 1.0\n",
      "epoch 946  acc: 1.0\n",
      "epoch 947  acc: 1.0\n",
      "epoch 948  acc: 1.0\n",
      "epoch 949  acc: 1.0\n",
      "epoch 950  acc: 1.0\n",
      "epoch 951  acc: 1.0\n",
      "epoch 952  acc: 1.0\n",
      "epoch 953  acc: 1.0\n",
      "epoch 954  acc: 1.0\n",
      "epoch 955  acc: 1.0\n",
      "epoch 956  acc: 1.0\n",
      "epoch 957  acc: 1.0\n",
      "epoch 958  acc: 1.0\n",
      "epoch 959  acc: 1.0\n",
      "epoch 960  acc: 1.0\n",
      "epoch 961  acc: 1.0\n",
      "epoch 962  acc: 1.0\n",
      "epoch 963  acc: 1.0\n",
      "epoch 964  acc: 1.0\n",
      "epoch 965  acc: 1.0\n",
      "epoch 966  acc: 1.0\n",
      "epoch 967  acc: 1.0\n",
      "epoch 968  acc: 1.0\n",
      "epoch 969  acc: 1.0\n",
      "epoch 970  acc: 1.0\n",
      "epoch 971  acc: 1.0\n",
      "epoch 972  acc: 1.0\n",
      "epoch 973  acc: 1.0\n",
      "epoch 974  acc: 1.0\n",
      "epoch 975  acc: 1.0\n",
      "epoch 976  acc: 1.0\n",
      "epoch 977  acc: 1.0\n",
      "epoch 978  acc: 1.0\n",
      "epoch 979  acc: 1.0\n",
      "epoch 980  acc: 1.0\n",
      "epoch 981  acc: 1.0\n",
      "epoch 982  acc: 1.0\n",
      "epoch 983  acc: 1.0\n",
      "epoch 984  acc: 1.0\n",
      "epoch 985  acc: 1.0\n",
      "epoch 986  acc: 1.0\n",
      "epoch 987  acc: 1.0\n",
      "epoch 988  acc: 1.0\n",
      "epoch 989  acc: 1.0\n",
      "epoch 990  acc: 1.0\n",
      "epoch 991  acc: 1.0\n",
      "epoch 992  acc: 1.0\n",
      "epoch 993  acc: 1.0\n",
      "epoch 994  acc: 1.0\n",
      "epoch 995  acc: 1.0\n",
      "epoch 996  acc: 1.0\n",
      "epoch 997  acc: 1.0\n",
      "epoch 998  acc: 1.0\n",
      "epoch 999  acc: 1.0\n"
     ]
    }
   ],
   "source": [
    "modellstm = train(epochs=150, lr=0.0002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_22606/489611986.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[1][i] = [word for word in word_tokenize(data[1][i]) if word not in stop_words]\n",
      "/tmp/ipykernel_22606/489611986.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[1][i] = [words_map[word] for word in data[1][i]]\n",
      "/tmp/ipykernel_22606/489611986.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[1][i] = [0] * (sentence_len - len(data[1][i])) + data[1][i]\n",
      "/tmp/ipykernel_22606/489611986.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[1][i] = torch.tensor(data[1][i])\n",
      "/tmp/ipykernel_22606/489611986.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[1][i] = [word for word in word_tokenize(data[1][i]) if word not in stop_words]\n",
      "/tmp/ipykernel_22606/489611986.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[1][i] = [words_map[word] for word in data[1][i]]\n",
      "/tmp/ipykernel_22606/489611986.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[1][i] = [0] * (sentence_len - len(data[1][i])) + data[1][i]\n",
      "/tmp/ipykernel_22606/489611986.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[1][i] = torch.tensor(data[1][i])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  acc: 0.6428571428571429\n",
      "epoch 1  acc: 0.9285714285714286\n",
      "epoch 2  acc: 0.9285714285714286\n",
      "epoch 3  acc: 0.9285714285714286\n",
      "epoch 4  acc: 0.9285714285714286\n",
      "epoch 5  acc: 1.0\n",
      "epoch 6  acc: 1.0\n",
      "epoch 7  acc: 1.0\n",
      "epoch 8  acc: 1.0\n",
      "epoch 9  acc: 1.0\n"
     ]
    }
   ],
   "source": [
    "modeltrans = train(yrmodel=\"trans\", lr=0.0001,epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 means spam, 0 means ham\n",
      "lstm model:  0.9991217255592346\n",
      "transformer model:  0.6610587239265442\n"
     ]
    }
   ],
   "source": [
    "sen = '''FreeMsg Hey there darling it's been 3 week's now and no word back! I'd like some fun you up for it still? Tb ok! XxX std chgs to send, to rcv'''\n",
    "\n",
    "data = [words_map[word] for word in word_tokenize(sen) if word not in stop_words]\n",
    "data = [0] * (sentence_len - len(data)) + data\n",
    "data = torch.tensor(data)\n",
    "data = torch.reshape(data,(1,-1))\n",
    "\n",
    "print(\"1 means spam, 0 means ham\")\n",
    "print(\"lstm model: \", modellstm(data).item())\n",
    "print(\"transformer model: \", modeltrans(data).item())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
