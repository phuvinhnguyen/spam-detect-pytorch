{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total samples:  5573\n",
      "ham:  4825\n",
      "spam:  748\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 2 artists>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = pd.read_csv('./spam_detection.csv', header=None)\n",
    "print(\"total samples: \", data[0].count())\n",
    "data = (data[0] == \"ham\").to_numpy()\n",
    "\n",
    "ham = data.sum()\n",
    "spam = data.size - ham\n",
    "\n",
    "print(\"ham: \", ham)\n",
    "print(\"spam: \", spam)\n",
    "\n",
    "plt.bar([\"ham\", \"spam\"], [ham, spam])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_map = {'\\0':0}\n",
    "sentence_len = 64\n",
    "data_dir = './spam_detection.csv'\n",
    "train_test_pro = 0.7\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def initData(data_directory = './spam_detection.csv'):\n",
    "    k = 0\n",
    "    data_ = {0 : [], 1 : []}\n",
    "    data = pd.read_csv(data_directory, header=None)\n",
    "\n",
    "    for i in range(len(data[0])):\n",
    "        data[1][i] = [word for word in word_tokenize(data[1][i]) if word not in stop_words]\n",
    "        for word in data[1][i]:\n",
    "            if word not in words_map:\n",
    "                words_map[word] = k\n",
    "                k += 1\n",
    "        data[1][i] = [words_map[word] for word in data[1][i]]\n",
    "        data[1][i] = [0] * (sentence_len - len(data[1][i])) + data[1][i]\n",
    "        data[1][i] = torch.tensor(data[1][i])\n",
    "        if data[0][i] == 'ham':\n",
    "            data_[0].append(data[1][i])\n",
    "        else:\n",
    "            data_[1].append(data[1][i])\n",
    "\n",
    "    len_ = min(len(data_[1]), len(data_[0]))\n",
    "\n",
    "    data_[0] = data_[0][1:len_]\n",
    "    data_[1] = data_[1][1:len_]\n",
    "    return data_, len_ - 1\n",
    "\n",
    "\n",
    "class SpamData(Dataset):\n",
    "    def __init__(self, data_directory, train=True, rt=0.7):\n",
    "        self.data_, self.len_ = initData(data_directory)\n",
    "        mid = (int) (self.len_*rt)\n",
    "        if train:\n",
    "            self.data_[0] = self.data_[0][0:mid]\n",
    "            self.data_[1] = self.data_[1][0:mid]\n",
    "            self.len_ = mid\n",
    "        else:\n",
    "            self.data_[0] = self.data_[0][mid:]\n",
    "            self.data_[1] = self.data_[1][mid:]\n",
    "            self.len_ = self.len_ - mid\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len_ * 2\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if (index % 2 == 1):\n",
    "            return 1, self.data_[1][index % self.len_]\n",
    "        return 0, self.data_[0][index % self.len_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model: int, dropout: float = 0.1, max_len: int = 5000):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
    "        pe = torch.zeros(max_len, 1, d_model)\n",
    "        pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = x + self.pe[:x.size(0)]\n",
    "        return self.dropout(x)\n",
    "\n",
    "class Transmodel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Transmodel, self).__init__()\n",
    "        embed_dim = 48\n",
    "        self.embed = nn.Embedding(len(words_map), embed_dim)\n",
    "        layer = nn.TransformerEncoderLayer(embed_dim, 4)\n",
    "        self.transen = nn.TransformerEncoder(layer, 4)\n",
    "        self.ln = nn.Linear(embed_dim * sentence_len, sentence_len)\n",
    "        self.lno = nn.Linear(sentence_len, 1)\n",
    "        self.pose = PositionalEncoding(embed_dim)\n",
    "\n",
    "    def forward(self, input):\n",
    "        r = self.embed(input)\n",
    "        r = self.pose(r)\n",
    "        r = torch.reshape(r, (input.size()[0],-1))\n",
    "        r = self.ln(r)\n",
    "        r = self.lno(r)\n",
    "        return torch.sigmoid(r)\n",
    "\n",
    "class LSTMmodel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LSTMmodel, self).__init__()\n",
    "        self.embed = nn.Embedding(len(words_map), 32)\n",
    "        self.lstm = nn.LSTM(32, 64, 4, batch_first=True)\n",
    "        self.ln = nn.Linear(64, 1)\n",
    "        self.lno = nn.Linear(sentence_len, 1)\n",
    "\n",
    "    def forward(self, input):\n",
    "        r = self.embed(input)\n",
    "        r = self.lstm(r)[0]\n",
    "        r = self.ln(r)\n",
    "        r = torch.reshape(r, (input.size()[0],-1))\n",
    "        r = self.lno(r)\n",
    "        return torch.sigmoid(r)\n",
    "    \n",
    "def train(yrmodel='lstm', epochs=2, lr=0.0005, batch_size=16):\n",
    "    data = SpamData(data_dir, True, 1)\n",
    "    data_test = SpamData(data_dir, True, 1)\n",
    "\n",
    "    model = None\n",
    "\n",
    "    if yrmodel == \"lstm\":\n",
    "        model = LSTMmodel()\n",
    "    else:\n",
    "        model = Transmodel()\n",
    "    data_test_size = len(data_test)\n",
    "\n",
    "    dataloader = DataLoader(data, batch_size=batch_size, shuffle=True)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    criteria = torch.nn.BCELoss()\n",
    "\n",
    "    for i in range(epochs):\n",
    "        for out, inp in dataloader:\n",
    "            out = torch.reshape(out, (-1,1)).float()\n",
    "            pred = model(inp)\n",
    "            loss = criteria(pred, out)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        if i % 1 == 0:\n",
    "            prob = 0\n",
    "            for j in range(len(data_test)):\n",
    "                out, inp = data_test[j]\n",
    "                with torch.no_grad():\n",
    "                    inp = torch.reshape(inp, (1, -1))\n",
    "                    pred = model(inp)\n",
    "                    a = (model(inp)-0.5)*(out-0.5)\n",
    "                    if a >= 0:\n",
    "                        prob += 1\n",
    "            \n",
    "            print(f\"epoch {i}  acc: {prob * 1.0 / data_test_size}\")\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  acc: 0.6157965194109772\n",
      "epoch 1  acc: 0.6144578313253012\n",
      "epoch 2  acc: 0.5281124497991968\n",
      "epoch 3  acc: 0.8145917001338688\n",
      "epoch 4  acc: 0.9263721552878179\n",
      "epoch 5  acc: 0.9578313253012049\n",
      "epoch 6  acc: 0.9390896921017403\n",
      "epoch 7  acc: 0.9551539491298527\n",
      "epoch 8  acc: 0.9765729585006694\n",
      "epoch 9  acc: 0.9819277108433735\n"
     ]
    }
   ],
   "source": [
    "modellstm = train(epochs=10, lr=0.0002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  acc: 0.5\n",
      "epoch 1  acc: 0.5\n",
      "epoch 2  acc: 0.5\n",
      "epoch 3  acc: 0.5\n",
      "epoch 4  acc: 0.6164658634538153\n",
      "epoch 5  acc: 0.8199464524765729\n",
      "epoch 6  acc: 0.7938420348058902\n",
      "epoch 7  acc: 0.7904953145917001\n",
      "epoch 8  acc: 0.8346720214190094\n",
      "epoch 9  acc: 0.8360107095046854\n",
      "epoch 10  acc: 0.8279785809906292\n",
      "epoch 11  acc: 0.8179384203480589\n",
      "epoch 12  acc: 0.8085676037483266\n",
      "epoch 13  acc: 0.8145917001338688\n",
      "epoch 14  acc: 0.8299866131191432\n",
      "epoch 15  acc: 0.8467202141900937\n",
      "epoch 16  acc: 0.8554216867469879\n",
      "epoch 17  acc: 0.8668005354752343\n",
      "epoch 18  acc: 0.8862115127175368\n",
      "epoch 19  acc: 0.9069611780455153\n",
      "epoch 20  acc: 0.9156626506024096\n",
      "epoch 21  acc: 0.9163319946452476\n",
      "epoch 22  acc: 0.9196787148594378\n",
      "epoch 23  acc: 0.9250334672021419\n",
      "epoch 24  acc: 0.9250334672021419\n",
      "epoch 25  acc: 0.9230254350736279\n",
      "epoch 26  acc: 0.9250334672021419\n",
      "epoch 27  acc: 0.9270414993306559\n",
      "epoch 28  acc: 0.9263721552878179\n",
      "epoch 29  acc: 0.928380187416332\n",
      "epoch 30  acc: 0.9323962516733602\n",
      "epoch 31  acc: 0.9364123159303882\n",
      "epoch 32  acc: 0.9370816599732262\n",
      "epoch 33  acc: 0.9404283801874164\n",
      "epoch 34  acc: 0.9410977242302544\n",
      "epoch 35  acc: 0.9424364123159303\n",
      "epoch 36  acc: 0.9457831325301205\n",
      "epoch 37  acc: 0.9471218206157965\n",
      "epoch 38  acc: 0.9497991967871486\n",
      "epoch 39  acc: 0.9544846050870147\n",
      "epoch 40  acc: 0.9598393574297188\n",
      "epoch 41  acc: 0.964524765729585\n",
      "epoch 42  acc: 0.9665327978580991\n",
      "epoch 43  acc: 0.9692101740294511\n",
      "epoch 44  acc: 0.9745649263721553\n",
      "epoch 45  acc: 0.9765729585006694\n",
      "epoch 46  acc: 0.9779116465863453\n",
      "epoch 47  acc: 0.9792503346720214\n",
      "epoch 48  acc: 0.9799196787148594\n",
      "epoch 49  acc: 0.9805890227576974\n",
      "epoch 50  acc: 0.9825970548862115\n",
      "epoch 51  acc: 0.9832663989290495\n",
      "epoch 52  acc: 0.9839357429718876\n",
      "epoch 53  acc: 0.9839357429718876\n",
      "epoch 54  acc: 0.9839357429718876\n",
      "epoch 55  acc: 0.9866131191432396\n",
      "epoch 56  acc: 0.9866131191432396\n",
      "epoch 57  acc: 0.9879518072289156\n",
      "epoch 58  acc: 0.9866131191432396\n",
      "epoch 59  acc: 0.9872824631860776\n"
     ]
    }
   ],
   "source": [
    "modeltrans = train(yrmodel=\"trans\", lr=0.00015,epochs=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 means spam, 0 means ham\n",
      "lstm model:  0.5147634744644165\n",
      "transformer model:  1.0\n"
     ]
    }
   ],
   "source": [
    "sen = '''FreeMsg Hey there darling it's been 3 week's now and no word back! I'd like some fun you up for it still? Tb ok! XxX std chgs to send, to rcv'''\n",
    "\n",
    "data = [words_map[word] for word in word_tokenize(sen) if word not in stop_words]\n",
    "data = [0] * (sentence_len - len(data)) + data\n",
    "data = torch.tensor(data)\n",
    "data = torch.reshape(data,(1,-1))\n",
    "\n",
    "print(\"1 means spam, 0 means ham\")\n",
    "print(\"lstm model: \", modellstm(data).item())\n",
    "print(\"transformer model: \", modeltrans(data).item())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
